# FuseML Tutorials

Test FuseML is simpler than one may think. Let's showcase some use cases.

## Example 1 - A simple logistic regression

Let's look at the example for MLflow model, being trained by MLflow and served with KFServing.
We assume both FuseML infrastructure and FuseML command-line are already installed, if not please check first the [quick start](quickstart.md) section.
To make your life easier there are a couple of variables that will help you to follow this tutorial.

### 1. Set the value of FUSEML_SERVER_URL, to point to the server URL:

```bash
export FUSEML_SERVER_URL=http//$(kubectl get VirtualService -n fuseml-core fuseml-core -o jsonpath="{.spec.hosts[0]}")
```

Set the GITEA URL's:

```bash
export GITEA_URL=http://$(kubectl get VirtualService -n gitea gitea -o jsonpath="{.spec.hosts[0]}")
export GITEA_ADMIN_USERNAME=$(kubectl get Secret -n fuseml-workloads gitea-creds -o jsonpath="{.data.username}" | base64 -d)
export GITEA_ADMIN_PASSWORD=$(kubectl get Secret -n fuseml-workloads gitea-creds -o jsonpath="{.data.password}" | base64 -d)
```

### 2. Get the example code

```bash
git clone https://github.com:fuseml/examples.git
cd fuseml-examples
```

### 3. Under models/mlflow-wines directory there is the example MLflow project. It's only slightly modified example based on the upstream MLflow public example [here](https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html).

### 4. Register the codeset

```bash
fuseml --url $FUSEML_SERVER_URL codeset register --name "mlflow-test" --project "mlflow-project-01" "models/mlflow-wines"
```

### 5. Check the result directly on the GITEA website. Login on `http://gitea.<YOUR FUSEML URL>` using username `dev` and password `changeme`. You should find
   a new organization named `mlflow-project-01` and a repo named `mlflow-test`.

### 6. Update the example to fit your setup

The workflow definition example has some hardcoded values that need to be changed for your specific environment. Namely, see the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values: these are the credentials to the S3 based minio store that was installed to your cluster by fuseml-installer.

To get these values from your cluster setup, run

```bash
export ACCESS=$(kubectl get secret -n fuseml-workloads mlflow-minio -o json| jq -r '.["data"]["accesskey"]' | base64 -d)
export SECRET=$(kubectl get secret -n fuseml-workloads mlflow-minio -o json| jq -r '.["data"]["secretkey"]' | base64 -d)

Now replace the original values in the pipeline-01.yaml example. You can do it by editing the file manually or by running following command:

sed -i -e "/AWS_ACCESS_KEY_ID/{N;s/value: [^ \t]*/value: $ACCESS/}" pipelines/pipeline-01.yaml
sed -i -e "/AWS_SECRET_ACCESS_KEY/{N;s/value: [^ \t]*/value: $SECRET/}" pipelines/pipeline-01.yaml
```

### 7. Create a workflow

Use the modified example workflow definition:

```bash
workflow=$(cat pipelines/pipeline-01.yaml)
fuseml workflow register --body "$(cat pipelines/pipeline-01.yaml)"
```

### 8. Assign the codeset to workflow

```bash
fuseml --url $FUSEML_SERVER_URL workflow assign --name mlflow-sklearn-e2e --codeset-name mlflow-test --codeset-project mlflow-project-01
``` 

### Monitoring the workflow from the command-line

Now that the Workflow is assigned to the Codeset, a new workflow run was created. To watch the workflow progress, check "workflow run" with:

```bash
fuseml --url $FUSEML_SERVER_URL workflow list-runs --workflow-name mlflow-sklearn-e2e
```

This command shows you detailed information about running workflow. Follow the url value under output section to see relevant Tekton PipelineRun which implements the workflow run.

Or browse to TEKTON_DASHBOARD_URL (http://tekton.<YOUR FUSEML INSTANCE URL>) to check all available PipelineRuns. Once the run is succeeded, new FuseML application will be created.

### 9. Use the prediction service

Once the application is created, check the applications list with:

```bash
fuseml --url $FUSEML_SERVER_URL application list
```

This should produce output similar to this one (notice the fake "example.io" domain here):

- name: mlflow-project-01-mlflow-test
    type: predictor
    description: Application generated by mlflow-sklearn-e2e workflow
    url: http://mlflow-project-01-mlflow-test.fuseml-workloads.example.io/v2/models/mlflow-project-01-mlflow-test/infer
    workflow: mlflow-sklearn-e2e

Use the URL from the new application to run the prediction. First, prepare the data

```bash
cat > data.json
{
    "inputs": [
    {
        "name": "input-0",
        "shape": [1, 11],
        "datatype": "FP32",
        "data": [
        [12.8, 0.029, 0.48, 0.98, 6.2, 29, 7.33, 1.2, 0.39, 90, 0.86]
        ]
    }
    ]
}
```

and pass the data to the the prediction service. Assuming the service URL was saved to PREDICTOR_URL, call:

```bash
curl -d @data.json http://$PREDICTOR_URL

The output should look like

{
    "model_name":"mlflow-project-01-mlflow-test",
    "model_version":null,
    "id":"44d5d037-052b-49b6-aace-1c5346a35004",
    "parameters":null,
    "outputs": [
    {
        "name":"predict",
        "shape":[1],
        "datatype":"FP32",
        "parameters":null,
        "data": [ 6.486344809506676 ]
    }
    ]
}
```

### 10. (Optional) Use the webapp example

Alternatively one may use a simple app we developed using [streamlit](https://streamlit.io/).

Assuming streamlit is already installed just run:

```bash
streamlit run https://raw.githubusercontent.com/fuseml/examples/main/webapps/wineapp.py
```

Follow the instructions presented in the webpage to make your own prediction with the FuseML application you just deployed.